import requests
import time

import requests
from typing import List

class AcademicAssistant:
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.general_knowledge_model = "google/flan-t5-base"
        self.academic_model = "google/flan-t5-base"

    def generate_general_answer(self, question: str) -> str:
        """Genera respuestas usando conocimiento general"""
        prompt = (
            "Como experto en Bioinform√°tica y Programaci√≥n, responde de manera detallada pero concisa:\n"
            f"Pregunta: {question}\n\n"
            "Incluye cuando sea relevante:\n"
            "- Explicaciones conceptuales\n"
            "- Contexto hist√≥rico\n"
            "- Aplicaciones pr√°cticas\n"
            "Respuesta (formato markdown):"
        )
        return self._call_hf_api(prompt, model=self.general_knowledge_model)

    def generate_academic_answer(self, question: str, context_chunks: List[dict]) -> str:
        """Combina contexto y conocimiento general"""
        context_text = "\n".join([chunk['text'] for chunk in context_chunks])
        
        prompt = (
            "Integra esta informaci√≥n con tu conocimiento profesional:\n"
            f"Contexto:\n{context_text}\n\n"
            f"Pregunta: {question}\n\n"
            "Instrucciones:\n"
            "1. Si el contexto es relevante, √∫salo como base\n"
            "2. Si es insuficiente, complementa con conocimiento general\n"
            "3. Estructura la respuesta en secciones claras\n"
            "Respuesta (markdown):"
        )
        return self._call_hf_api(prompt, model=self.academic_model)

    def _call_hf_api(self, prompt: str, model: str, max_length: int = 800) -> str:
        """API mejorada con manejo de modelos y errores"""
        try:
            response = requests.post(
                f"https://api-inference.huggingface.co/models/{model}",
                headers={"Authorization": f"Bearer {self.api_key}"},
                json={
                    "inputs": prompt,
                    "parameters": {
                        "max_length": max_length,
                        "temperature": 0.5,
                        "do_sample": True,
                        "top_k": 50
                    }
                },
                timeout=15
            )
            
            if response.status_code == 200:
                return response.json()[0]['generated_text']
            return f"üîç Error en la API: {response.text}"
            
        except requests.exceptions.Timeout:
            return "‚è≥ Tiempo excedido procesando la solicitud"
        except Exception as e:
            return f"‚ö†Ô∏è Error de conexi√≥n: {str(e)}"


    def evaluate_triviality(self, question: str) -> bool:
        """Eval√∫a si la pregunta es trivial/com√∫n"""
        prompt = (
            "Clasifica la pregunta como 'True' (trivial) o 'False' (acad√©mica):\n"
            "Ejemplos:\n"
            "'Hola' ‚Üí True\n"
            "'Explica la fotos√≠ntesis' ‚Üí False\n"
            f"Pregunta: {question}\nRespuesta:"
        )
        response = self._call_hf_api(prompt, max_length=20)
        return "true" in response.lower()

    def generate_friendly_response(self, message: str) -> str:
        """Respuesta amable para preguntas no acad√©micas"""
        prompt = (
            "Eres un asistente acad√©mico amable. Responde brevemente:\n"
            f"Usuario dice: {message}\n"
            "Respuesta (1-2 l√≠neas, formato natural):"
        )
        return self._call_hf_api(prompt)

    def _call_hf_api(self, prompt: str, max_length: int = 500) -> str:
        """Llama a la API con reintentos y timeouts controlados"""
        max_retries = 3
        for attempt in range(max_retries):
            try:
                response = requests.post(
                    "https://api-inference.huggingface.co/models/google/flan-t5-base",
                    headers={"Authorization": f"Bearer {self.api_key}"},
                    json={
                        "inputs": prompt,
                        "parameters": {
                            "max_length": max_length,
                            "temperature": 0.3,
                            "do_sample": True
                        }
                    },
                    timeout=10  # Reducir timeout de API
                )
                
                if response.status_code == 200:
                    return response.json()[0]['generated_text']
                    
                # Manejo espec√≠fico de errores HTTP
                return f"Error en API (C√≥digo {response.status_code}): {response.text}"
                
            except (requests.exceptions.Timeout, requests.exceptions.ConnectionError):
                if attempt == max_retries - 1:
                    return "Error de conexi√≥n: Tiempo excedido"
                time.sleep(2 ** attempt)  # Espera exponencial
                
            except Exception as e:
                return f"Error inesperado: {str(e)}"

